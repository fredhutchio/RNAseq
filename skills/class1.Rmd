---
title: 'Bulk RNAseq analysis, Class 1: Introduction to RNAseq data'
output: github_document
---

<!--class1.md is generated from class1.Rmd. Please edit that file -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objectives

Welcome to Bulk RNAseq Analysis from fredhutch.io!
This course introduces you the following steps in performing RNAseq analysis:
- project organization and access via Hutch data storage and compute
- data pre-processing and quality assessment
- read mapping and summary to quantify genes/transcripts
- differential gene analysis and visualization

This course assumes a general knowledge of both the Unix shell and R statistical programming.
See [Prerequisites](../README#prerequisites) for more information about what concepts and skills should be familiar to you before this course.

For more information about RNAseq and genomics work, 
please see the resources for [RNA approaches](https://sciwiki.fredhutch.org/generation/datagen_rnaApproaches) 
in the Fred Hutch Biomedical Data Science Wiki.

Before proceeding with these training materials,
please ensure you have installed XXX as described [here](http://www.fredhutch.io/software/).

By the end of this class, you should be able to:
- Organize files (data, code, results) associated with genomics projects
- Run command line genomics software on the Fred Hutch shared compute cluster, `rhino`
- Assess the quality of genomic data
- Trim and filter raw genomic data 

## About the data

The data and associated research questions motivate all subsequent decisions in the analysis.

Human and mouse data from ENCODE project

FIXME diagram of study design

3x3 comparison of two tissues

Work through human materials in class,
mouse data provided and available for homework and personal exploration

For first two classes,
only work with single sample (save time).
only chromosome 9, result in sparse gene matrix

Intermediate results available for reference

Pre-analyzed data for all samples provided for third and fourth classes.

whole genome, complete count matrix for multiple samples; result is DGE across multiple samples

## Getting set up

For this class,
we'll be executing steps in an RNAseq workflow using command-line software on the Fred Hutch on-premise shared compute cluster maintained by Scientific Computing.

You can access the cluster by logging on to `rhino` using the instructions [here](https://sciwiki.fredhutch.org/compdemos/first_rhino/).
We recommend connecting to VPN and then using `ssh username@rhino@fhcrc.org` in your shell to access the cluster.

Why are we using the cluster?
- access to software and example data files
- may not be possible to install/run these programs on your own computer
- consistent among everyone in the class (reproducible!)

> Galaxy is another option for running genomics software,
> though it has its own limitations.
> Learn more about accessing Galaxy [here](https://sciwiki.fredhutch.org/compdemos/galaxy-on-prem/).

This class is designed to walk you through the steps of an RNAseq analysis,
which involves running each program individually.
While this is effective for learning how software works and confirming initial results are as expected,
it isn't especially efficient for processing large numbers of files.
We'll periodically identify methods and tools that represent how these tasks operate at scale (across an entire experiment),
with an emphasis on reproducibility of your computational methods.
As you think about the way you're conducting your analyses,
consider the following goals for reproducibility:
- record keeping for reporting methods in a manuscript
- helps you rework analysis (in the future, for more samples, or to change methods)
- allows other people (in your lab, manuscript reviewers, other scientists) to recreate your results

## Overview of workflow

Overview of workflow

FIXME diagram of workflow (from concepts)

Questions to ask at each step of the analysis:
- Are data organized and formatted appropriately?
- What characteristics of the data type and experimental design need to be considered?
- Are the results reliable, verifiable, and consistent with expectations?

## Project organization

Project-based file management

Types of files
- data and metadata
- intermediate results
- final output
- logs (commands and output from programs)

How genomics projects differ, with data stored separately

For this class:
- file storage reflects standard practices of data generated by Shared Resources
- project organization reflects workflow and common practices at the Hutch
- we'll access and inspect files via the command line

> accessing and transferring data stored in Hutch network drive;
> Mac vs Windows

Locate the project files

```bash
cd /shared/biodata/example_data
ls
cat README.md
```

READMEs:
- share information about a project or dataset
- you should write one for your own projects, too

[Guide to writing READMEs](https://data.research.cornell.edu/content/readme)

Viewing the "raw" data files:

```bash
cd data
ls
```

About these data:
- paired-end
- fastq format
- some pre-processing already done (adapters trimmed)
- gzipped (ends in `.gz`), file compression that reduces file size

View data:

```bash
zcat ENCFF850ZLY.fastq.gz | head
cd ..
```

Project organization for this class,
via already completed project:

```bash
ls -lh rnaseq_class
```

> We'll discuss reference data (e.g., gene sequences and annotations)
> and metadata (information about experimental design used in data analysis)
> in later classes.

## Assessing data quality

Run the command `grabnode` and then select the following parameters:
1 core, 20 GB, 1 day, and N GPU.

For more information on running interactive jobs with grabnode,
please see [this entry](https://sciwiki.fredhutch.org/compdemos/first_rhino/#logging-on-to-gizmo-via-grabnode)
from the SciWiki.

Let's load the first module we'll be using to assess the quality of our data:

```bash
ml FastQC
```

Remember that capitalization matters!
`ml` stands for `module load`,
which makes the software installed on the cluster available for use.
For more information on working with modules,
please see [this section](https://sciwiki.fredhutch.org/compdemos/first_rhino/#loading-software)
of the SciWiki.

[FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)
is software that supports quality control (QC) of fastq sequence data,
such as those 

running command-line genomics programs

> note about [tmux](https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/) to allow continued work while also running interactive commands



## Trimming and filtering data

The approach we'll be using in our main workflow performs quality assessment of data as we map the reads,
which prevents any low-quality data from being included in subsequent analysis.
Depending on the nature of your data 
(e.g., model system) 
and experimental design,
you may instead choose to filter and trim your data based on quality scores (and perhaps other parameters).

trimming and quality filtering

filtering (cutadapt)

```bash
ml cutadapt
```


only for de novo assembly, or other special cases

follow-up QC (multiQC)

fastqc
MultiQC: https://multiqc.info

## Wrapping up

saving work

accessing work again

review objectives

preview objectives for next class

Reference materials:
- https://datacarpentry.org/organization-genomics/
- Section 4 onwards 
https://bioconductor.org/packages/release/workflows/vignettes/RNAseq123/inst/doc/designmatrices.html

## On your own

